{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f735f4-6354-4b4d-9e4c-c210e6419ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers -q\n",
    "!pip install datasets -q\n",
    "!pip install spacy -q\n",
    "!pip install wordcloud -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51274e40-8d46-4d21-82cb-9285a275231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# NLP & Text Preprocessing\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "\n",
    "# Scikit-learn: Data Handling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Scikit-learn: Text Processing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Scikit-learn: Evaluation Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Scikit-learn: Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b6459f-5794-40ef-9312-d2bb9391e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kagglehub -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a27c505-a245-4b1f-accd-3fcd3724415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "email_path = kagglehub.dataset_download(\"naserabdullahalam/phishing-email-dataset\")\n",
    "\n",
    "print(\"Path to Email dataset files:\", email_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0906ebda-67f9-4327-9c92-b577b4d9368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# List all files in the dataset folder\n",
    "email_files = os.listdir(email_path)\n",
    "\n",
    "print(\"Files in Email dataset:\", email_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d97ede-fd3b-4162-a9fc-5023c94161b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df = pd.read_csv(f'{email_path}/Ling.csv')\n",
    "print(email_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d3563c-c6f2-48b7-9a41-15bc36fc10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d3f7f-4385-4964-9427-ee18daabf0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a115b-dced-412b-97b1-07b22e567753",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc40202-2393-4690-9991-268ca272cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cfac6b-920b-4848-acbd-e0849eaf738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df['email'] = email_df['subject'] + ' ' + email_df['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67feac7-2e3d-4c50-8b0e-8f2b7705ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up unused columns\n",
    "email_df = email_df.drop(columns=['subject', 'body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11af6ae-0a99-4fd6-b02a-a8a736fed9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252293f0-e1ed-4d7d-8701-adc814343b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3433b29b-c0ef-49aa-8006-cd3829cafa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ef516-336b-4e55-b196-bf3fb56b6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e40f4e1-3e2e-4c90-8eb8-71f7bcce9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4a52ff-a65e-47ea-9077-37a43deb0147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6974d1f-560d-42ef-b60b-25c4d18e6ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def preprocess_email(text):\n",
    "    # Handle Empty values\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Remove HTML tags\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    text = soup.get_text(separator=' ')\n",
    "\n",
    "    # Replace Links with [URL]\n",
    "    url_pattern = r'(https?://\\S+|www\\.\\S+)'\n",
    "    text = re.sub(url_pattern, '[URL]', text)\n",
    "\n",
    "    # 4. Remove Email Addresses\n",
    "    email_pattern = r'\\S+@\\S+'\n",
    "    text = re.sub(email_pattern, '[EMAIL]', text)\n",
    "\n",
    "    # Process with spaCy\n",
    "    doc = nlp(text.lower())\n",
    "\n",
    "    # Remove stopwords + non-alphabetic + lemmatize\n",
    "    tokens = [\n",
    "      token.lemma_\n",
    "      for token in doc\n",
    "      if (token.is_alpha or token.text in ['[URL]', '[EMAIL]']) and not token.is_stop\n",
    "    ]\n",
    "\n",
    "    # Join tokens back to string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "email_df['cleaned_email'] = email_df['email'].apply(preprocess_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3abbf3-a87e-48ef-9163-01875cb380ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4601a5-15a5-4351-9fa7-73394a1a01f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the most frequent words per category using bar plots\n",
    "real_emails = ' '.join(email_df[email_df['label']==0]['cleaned_email'])\n",
    "spam_emails = ' '.join(email_df[email_df['label']==1]['cleaned_email'])\n",
    "\n",
    "def most_common_words(text, title, n, filename):\n",
    "    if not text:\n",
    "        print(f'No words found for {title}')\n",
    "        return\n",
    "\n",
    "    words = text.split()  # Split the text into words\n",
    "    counter = Counter(words)\n",
    "    common = counter.most_common(n) # Get the top n most common words\n",
    "\n",
    "    if not common:\n",
    "        print(f'No words found for {title}')\n",
    "        return\n",
    "\n",
    "    words, counts = zip(*common)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(words, counts, color='#33f')\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # âœ… Save as image\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "most_common_words(real_emails, 'Top Real Words', 20, 'top_real_Email_Words.png')\n",
    "most_common_words(spam_emails, 'Top Spam Words', 20, 'top_spam_Email_Words.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f08373-2a3b-4ea8-b5be-76f6042044b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the most frequent words per category using word clouds\n",
    "real_WordCloud = WordCloud(width=800, height=400, background_color='white', colormap='Greens').generate(real_emails)\n",
    "spam_WordCloud = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate(spam_emails)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(real_WordCloud, interpolation='bilinear')\n",
    "plt.title('Most frequent Real Email Words')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(spam_WordCloud, interpolation='bilinear')\n",
    "plt.title('Most frequent Spam Words')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# âœ… Save as image\n",
    "plt.savefig('word_cloud.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd849519-3d61-4c99-9415-8c8949f28365",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = email_df.copy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9ac02-3e55-4800-917a-76ddd9fea34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expansion 01\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train-Test Split\n",
    "X = data['cleaned_email']\n",
    "y = data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23, stratify=y)\n",
    "\n",
    "# Build Pipelines with Multiple Models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(solver='saga', max_iter=1000, random_state=23),\n",
    "    'Linear SVM': LinearSVC(random_state=23),\n",
    "    'Multinomial NB': MultinomialNB(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=23),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=23)\n",
    "}\n",
    "\n",
    "result = {}\n",
    "\n",
    "for name, regressor in models.items():\n",
    "    # Note: Using Pipeline to ensure vectorization is fit only on training data\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', TfidfVectorizer(ngram_range=(1,2), max_df=0.8, min_df=5)),\n",
    "        ('regressor', regressor)\n",
    "    ])\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    result[name] = accuracy\n",
    "\n",
    "    print(f'Model: {name}')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Classification Report:\\n{classification_report(y_test, y_pred)}\\n')\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a15b176-c484-4946-aa33-69839b31f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expansion 02\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train-Test Split\n",
    "X = data['cleaned_email']\n",
    "y = data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23, stratify=y)\n",
    "\n",
    "# Expanded Model Dictionary\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(solver='saga', max_iter=1000, random_state=23),\n",
    "    'Linear SVM': LinearSVC(random_state=23),\n",
    "    'Multinomial NB': MultinomialNB(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=23),\n",
    "    'SGD Classifier': SGDClassifier(loss='hinge', penalty='l2', random_state=23),\n",
    "    'Passive Aggressive': PassiveAggressiveClassifier(max_iter=1000, random_state=23),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=23)\n",
    "}\n",
    "\n",
    "result = {}\n",
    "\n",
    "for name, regressor in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', TfidfVectorizer(ngram_range=(1,2), max_df=0.8, min_df=5)),\n",
    "        ('regressor', regressor)\n",
    "    ])\n",
    "\n",
    "    # Train and evaluate\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    result[name] = accuracy\n",
    "\n",
    "    print(f'Model: {name}')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Classification Report\\n {classification_report(y_test, y_pred)}\\n')\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9361b400-192e-41ca-90ba-00e58241cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expansion 03\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train-Test Split\n",
    "X = data['cleaned_email']\n",
    "y = data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23, stratify=y)\n",
    "\n",
    "# Expanded Model Dictionary\n",
    "models = {\n",
    "    # Linear & Fast Models\n",
    "    'Logistic Regression': LogisticRegression(solver='saga', max_iter=1000, random_state=23),\n",
    "    'Linear SVM': LinearSVC(random_state=23),\n",
    "    'Ridge Classifier': RidgeClassifier(random_state=23),\n",
    "    'SGD Classifier': SGDClassifier(loss='modified_huber', random_state=23), # modified_huber gives probas\n",
    "    \n",
    "    # Naive Bayes (Standard for Text)\n",
    "    'Multinomial NB': MultinomialNB(),\n",
    "    'Complement NB': ComplementNB(), # Better for imbalanced text data\n",
    "    \n",
    "    # Tree Ensembles\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=23),\n",
    "    'Extra Trees': ExtraTreesClassifier(n_estimators=100, n_jobs=-1, random_state=23),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=23),\n",
    "    \n",
    "    # Gradient Boosting (State-of-the-art)\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=23),\n",
    "    'LightGBM': LGBMClassifier(random_state=23, verbose=-1)\n",
    "}\n",
    "\n",
    "result = {}\n",
    "\n",
    "for name, regressor in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', TfidfVectorizer(ngram_range=(1,2), max_df=0.8, min_df=5)),\n",
    "        ('regressor', regressor)\n",
    "    ])\n",
    "\n",
    "    # Train and evaluate\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    result[name] = accuracy\n",
    "\n",
    "    print(f'Model: {name}')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Classification Report:\\n {classification_report(y_test, y_pred)}\\n')\n",
    "    print('=' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f11eb7-515e-4b2c-a6be-a177ab6aac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Expanded\n",
    "# Train-Test Split\n",
    "X = data['cleaned_email']\n",
    "y = data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23, stratify=y)\n",
    "\n",
    "# Build Pipelines with Multiple Models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(solver='saga', max_iter=1000, random_state=23),\n",
    "    'SVM': LinearSVC(random_state=23)\n",
    "}\n",
    "\n",
    "result = {}\n",
    "\n",
    "for name, regressor in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', TfidfVectorizer(ngram_range=(1,2), max_df=0.8, min_df=5)),\n",
    "        ('regressor', regressor)\n",
    "    ])\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    result[name] = accuracy\n",
    "\n",
    "    print(f'Model: {name}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Classification Report\\n {classification_report(y_test, y_pred)}\\n')\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e39fc01-19a4-48eb-954a-4b857b72a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best model\n",
    "best_model = max(result, key=result.get)\n",
    "best_accuracy = result[best_model]\n",
    "print(f'The best model is {best_model}, with an accuracy of {best_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524cf310-31be-4f66-b235-5873e22b9df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "for name, regressor in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', TfidfVectorizer(ngram_range=(1,2), max_df=0.8, min_df=5)),\n",
    "        ('regressor', regressor)\n",
    "    ])\n",
    "\n",
    "# Train and evaluate the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[1, 0])\n",
    "    ConfusionMatrixDisplay(cm, display_labels=['Spam Emails', 'Real Emails']).plot(cmap='Blues', ax=ax)\n",
    "    plt.title(f'Confusion Matrix: {name}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # âœ… Save as image\n",
    "    plt.savefig(f'confusion_matrix_{name.replace(\" \", \"_\").lower()}.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1edbd-f11d-44b3-b476-affbcd3f5ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Model Accuracies\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=result.values(), y=result.keys(), color='#33f')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Models')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.tight_layout()\n",
    "\n",
    "# âœ… Save as image\n",
    "plt.savefig('compare_model_accuracy.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c7bd0e-18fd-4b81-8b9b-10d7a733226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on real data\n",
    "sample_emails=[\n",
    "    'CONGRATULATIONS! Your email address has been selected as the winner of the $1,000,000 Microsoft Promotion. To claim your prize, reply with your bank details immediately.',\n",
    "    'Hi Team, please find the minutes of our last meeting attached. We need to finalize the project budget by Friday. Let\\'s meet on Zoom at 2 PM to discuss.',\n",
    "    'webcam dating is hot - - - - - - - - - - - - - - - - please no more'\n",
    "]\n",
    "\n",
    "cleaned_samples = [preprocess_email(email) for email in sample_emails]\n",
    "\n",
    "best_model = Pipeline([\n",
    "    ('preprocessor', TfidfVectorizer()),\n",
    "    ('regressor', LinearSVC(random_state=23))\n",
    "])\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "preds = best_model.predict(cleaned_samples)\n",
    "\n",
    "for i, (j, k) in enumerate(zip(sample_emails, preds)):\n",
    "    label = \"SPAM ðŸš¨\" if k == 1 else \"REAL âœ…\"\n",
    "    print(f'\\n{i+1}. Email: {j}')\n",
    "    print(f'Prediction: {label} (Class {k})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4360af47-b7b2-4a80-9dbc-f4da2c45e8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model after training\n",
    "from joblib import dump\n",
    "dump(pipeline, 'model.joblib')\n",
    "\n",
    "print('âœ… Pipeline trained and saved as model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
