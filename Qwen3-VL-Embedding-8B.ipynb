{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f555754d-71fd-485d-83ce-3c5c142e6acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen3-VL-Embedding-8B\")\n",
    "model = AutoModelForImageTextToText.from_pretrained(\"Qwen/Qwen3-VL-Embedding-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16220564-1402-44c9-8a2f-64d6a0fb5eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phishing classified as Kinda Legitimate, \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def classify_email_robust(email_body):\n",
    "    # 1. Use a specific \"Probing\" instruction for the email.\n",
    "    # This triggers the model's 'Classification' weights instead of just 'Topic' weights.\n",
    "    query_instruction = \"Instruct: Analyze this email for potential security threats. Is it a phishing attempt or a legitimate message?\\nQuery: \"\n",
    "    \n",
    "    # 2. Use detailed descriptors for labels. \n",
    "    # Generic labels like \"Phishing\" are too short for stable math. \n",
    "    # Detailed labels create a larger 'target' in vector space.\n",
    "    labels = [\n",
    "        \"A malicious phishing email containing urgent threats, suspicious links, or credential harvesting.\",\n",
    "        \"A safe, legitimate, and professional business email communication.\"\n",
    "    ]\n",
    "    \n",
    "    # 3. Combine inputs: [Instruction + Email, Label 1, Label 2]\n",
    "    texts = [f\"{query_instruction}{email_body}\"] + labels\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = processor(text=texts, padding=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        \n",
    "        # KEY FIX: Access the [EOS] token embedding (the last token in the sequence).\n",
    "        # We use the attention mask to find the last valid token for each text.\n",
    "        last_hidden_states = outputs.hidden_states[-1]\n",
    "        \n",
    "        # Get the index of the last non-padding token\n",
    "        last_token_indices = inputs.attention_mask.sum(dim=1) - 1\n",
    "        \n",
    "        # Extract the EOS embeddings\n",
    "        embeddings = last_hidden_states[torch.arange(last_hidden_states.size(0)), last_token_indices]\n",
    "        \n",
    "        # Normalize for Cosine Similarity\n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "    # 4. Compare the Email Vector to the Label Vectors\n",
    "    email_vec = embeddings[0:1]\n",
    "    label_vecs = embeddings[1:]\n",
    "\n",
    "    # Calculate similarity and apply a temperature scale (20.0) \n",
    "    # This amplifies small mathematical differences into clear probabilities.\n",
    "    logits = torch.matmul(email_vec, label_vecs.T) * 20.0\n",
    "    probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "\n",
    "    return {\n",
    "        \"Phishing\": probs[0],\n",
    "        \"Legitimate\": probs[1],\n",
    "        \"Result\": \"Phishing\" if probs[0] > probs[1] else \"Legitimate\"\n",
    "    }\n",
    "\n",
    "# --- TEST ---\n",
    "email_content = \"\"\"\n",
    "Subject: Project Handover: Rackspace Onboarding Documents\n",
    "Body: Hi Sarah, attached are the final signed contracts and project requirements for the Joshua onboarding. Their point of contact is Mark Jensen. Let's touch base tomorrow morning to walk through https://youssouf.pickup-distrib.com/ the implementation timeline. Best, Dave.\n",
    "\"\"\"\n",
    "result = classify_email_robust(email_content)\n",
    "print(f\"Final Decision: {result['Result']}\")\n",
    "print(f\"Confidence - Phishing: {result['Phishing']:.2%}, Legit: {result['Legitimate']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b50ac5d-0584-4b7b-80d0-59d4ff95b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phishing classified as Kinda Legitimate, \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def classify_multimodal_email(email_body, image_name=None):\n",
    "    images = []\n",
    "    image_token = \"\"\n",
    "    \n",
    "    # 1. Load the local image\n",
    "    if image_name and os.path.exists(image_name):\n",
    "        # Open the image and ensure it's in RGB format\n",
    "        img = Image.open(image_name).convert(\"RGB\")\n",
    "        images = [img]\n",
    "        # Placeholder required for Qwen3-VL to attend to the image\n",
    "        image_token = \"<|vision_start|><|image_pad|><|vision_end|>\\n\"\n",
    "    \n",
    "    # 2. Construct the multimodal prompt\n",
    "    # We tell the model to consider both visual and textual cues\n",
    "    query_instruction = (\n",
    "        f\"Instruct: Analyze this email and image for security threats. \"\n",
    "        f\"Is this a phishing attempt or a legitimate message?\\n\"\n",
    "        f\"Query: {image_token}{email_body}\"\n",
    "    )\n",
    "    \n",
    "    labels = [\n",
    "        \"A malicious phishing email containing fraudulent visual elements, urgent threats, or suspicious links.\",\n",
    "        \"A safe, legitimate, and professional business email communication.\"\n",
    "    ]\n",
    "    \n",
    "    texts = [query_instruction] + labels\n",
    "    \n",
    "    # 3. Process inputs\n",
    "    inputs = processor(\n",
    "        text=texts, \n",
    "        images=images if images else None, \n",
    "        padding=True, \n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        \n",
    "        # Use the [EOS] token embedding (the last token in the sequence)\n",
    "        last_hidden_states = outputs.hidden_states[-1]\n",
    "        last_token_indices = inputs.attention_mask.sum(dim=1) - 1\n",
    "        embeddings = last_hidden_states[torch.arange(last_hidden_states.size(0)), last_token_indices]\n",
    "        \n",
    "        # Normalize for similarity comparison\n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "    # 4. Compare Email Vector to Label Vectors\n",
    "    email_vec = embeddings[0:1]\n",
    "    label_vecs = embeddings[1:]\n",
    "\n",
    "    # Calculate similarity with a temperature scale of 20.0 to sharpen decisions\n",
    "    logits = torch.matmul(email_vec, label_vecs.T) * 20.0\n",
    "    probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "\n",
    "    return {\n",
    "        \"Phishing\": probs[0],\n",
    "        \"Legitimate\": probs[1],\n",
    "        \"Result\": \"Phishing\" if probs[0] > probs[1] else \"Legitimate\"\n",
    "    }\n",
    "\n",
    "# --- TEST ---\n",
    "# Ensure 'image_cloud.png' is in the same folder as this notebook\n",
    "image_file = \"image_cloud.png\" \n",
    "\n",
    "email_content = \"\"\"\n",
    "Subject: Urgent: Verify your Rackspace credentials\n",
    "Body: We have detected a suspicious login attempt on your account. \n",
    "Please view the attached screenshot and verify your identity immediately \n",
    "at https://youssouf.pickup-distrib.com/verify-account.\n",
    "\"\"\"\n",
    "\n",
    "result = classify_multimodal_email(email_content, image_name=image_file)\n",
    "\n",
    "print(f\"Final Decision: {result['Result']}\")\n",
    "print(f\"Confidence - Phishing: {result['Phishing']:.2%}, Legit: {result['Legitimate']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b84e69d-1fb2-423b-9e44-cf0267f45342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def classify_multimodal_email(email_body, image_name=None):\n",
    "    images = []\n",
    "    image_token = \"\"\n",
    "    \n",
    "    # 1. Load the local image\n",
    "    if image_name and os.path.exists(image_name):\n",
    "        # Open the image and ensure it's in RGB format\n",
    "        img = Image.open(image_name).convert(\"RGB\")\n",
    "        images = [img]\n",
    "        # Placeholder required for Qwen3-VL to attend to the image\n",
    "        image_token = \"<|vision_start|><|image_pad|><|vision_end|>\\n\"\n",
    "    \n",
    "    # 2. Construct the multimodal prompt\n",
    "    # We tell the model to consider both visual and textual cues\n",
    "    query_instruction = (\n",
    "        f\"Instruct: Analyze this email and image for security threats. \"\n",
    "        f\"Is this a phishing attempt or a legitimate message?\\n\"\n",
    "        f\"Query: {image_token}{email_body}\"\n",
    "    )\n",
    "    \n",
    "    labels = [\n",
    "        \"A malicious phishing email containing fraudulent visual elements, urgent threats, or suspicious links.\",\n",
    "        \"A safe, legitimate, and professional business email communication.\"\n",
    "    ]\n",
    "    \n",
    "    texts = [query_instruction] + labels\n",
    "    \n",
    "    # 3. Process inputs\n",
    "    inputs = processor(\n",
    "        text=texts, \n",
    "        images=images if images else None, \n",
    "        padding=True, \n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        \n",
    "        # Use the [EOS] token embedding (the last token in the sequence)\n",
    "        last_hidden_states = outputs.hidden_states[-1]\n",
    "        last_token_indices = inputs.attention_mask.sum(dim=1) - 1\n",
    "        embeddings = last_hidden_states[torch.arange(last_hidden_states.size(0)), last_token_indices]\n",
    "        \n",
    "        # Normalize for similarity comparison\n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "    # 4. Compare Email Vector to Label Vectors\n",
    "    email_vec = embeddings[0:1]\n",
    "    label_vecs = embeddings[1:]\n",
    "\n",
    "    # Calculate similarity with a temperature scale of 20.0 to sharpen decisions\n",
    "    logits = torch.matmul(email_vec, label_vecs.T) * 20.0\n",
    "    probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "\n",
    "    return {\n",
    "        \"Phishing\": probs[0],\n",
    "        \"Legitimate\": probs[1],\n",
    "        \"Result\": \"Phishing\" if probs[0] > probs[1] else \"Legitimate\"\n",
    "    }\n",
    "\n",
    "# --- TEST ---\n",
    "# Ensure 'image_cloud.png' is in the same folder as this notebook\n",
    "image_file = \"image_cloud.png\" \n",
    "\n",
    "email_content = \"\"\"\n",
    "Subject: Urgent: Verify your Rackspace credentials\n",
    "Body: We have detected a suspicious login attempt on your account. \n",
    "Please view the attached screenshot and verify your identity immediately \n",
    "at https://youssouf.pickup-distrib.com/verify-account.\n",
    "\"\"\"\n",
    "\n",
    "result = classify_multimodal_email(email_content, image_name=image_file)\n",
    "\n",
    "print(f\"Final Decision: {result['Result']}\")\n",
    "print(f\"Confidence - Phishing: {result['Phishing']:.2%}, Legit: {result['Legitimate']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c96587-8353-4ea4-b99b-421f0375f124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
